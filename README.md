# pytorch-fresh-fruit-classification-fresh-vs-rotten
This project is based on  training and validating computer vision models for fruit quality detection, automated sorting, and AI-based freshness monitoring

# ğŸ Fresh vs Rotten Fruit Classification (Multi-Task Learning)

This project implements a **multi-task deep learning system** that simultaneously:

* **Identifies the type of fruit** (e.g. Apple, Banana, Strawberry)
* **Determines its freshness state** (Fresh or Rotten)

using a **shared CNN backbone with task-specific heads**. The model is trained using **PyTorch** and leverages **transfer learning with ResNet50**.

---

## ğŸ“Œ Project Motivation

In real-world food quality inspection systems (e.g. smart agriculture, retail automation, food safety), it is often insufficient to only classify *what* an object is. We also need to know *its condition*.

Rather than training two separate models, this project adopts **multi-task learning**, allowing:

* Shared visual understanding of fruits
* Better generalization
* Reduced model size and training cost

---

## ğŸ§  Model Architecture

### ğŸ”¹ Backbone

* **ResNet50 (ImageNet pretrained)**
* Early layers frozen for stability
* Last block (layer4) fine-tuned

### ğŸ”¹ Shared Representation

```text
Image â†’ ResNet50 â†’ Shared MLP (512-dim)
```

### ğŸ”¹ Task Heads

* **Fruit Classification Head** â†’ Multi-class (Apple, Banana, Strawberry, â€¦)
* **Freshness Classification Head** â†’ Binary (Fresh / Rotten)

```text
Shared Features
   â”œâ”€â”€ Fruit Head â†’ CrossEntropyLoss
   â””â”€â”€ Freshness Head â†’ CrossEntropyLoss
```

Total loss is computed as:

```math
L = L_fruit + L_freshness
```

---

## ğŸ—‚ Dataset Structure

Dataset is automatically downloaded from Kaggle and organized as:

```text
Fruit Freshness Dataset/
â”œâ”€â”€ Apple/
â”‚   â”œâ”€â”€ Fresh/
â”‚   â””â”€â”€ Rotten/
â”œâ”€â”€ Banana/
â”‚   â”œâ”€â”€ Fresh/
â”‚   â””â”€â”€ Rotten/
â””â”€â”€ Strawberry/
    â”œâ”€â”€ Fresh/
    â””â”€â”€ Rotten/
```

Each image path encodes both labels:

* **Fruit class** â†’ folder name
* **Freshness state** â†’ sub-folder name

---

## ğŸ”„ Data Processing & Augmentation

### Training Augmentations

Applied *randomly per epoch* to improve robustness:

* Resize (224 Ã— 224)
* Random Horizontal & Vertical Flip
* Random Rotation (Â±45Â°)
* Gaussian Blur
* Sharpness Adjustment
* ImageNet Normalization

> âš ï¸ Validation data uses **no augmentation**, only resizing and normalization.

---

## ğŸ§ª Data Splitting & Leakage Prevention

To prevent **data leakage**:

* Image filenames are deduplicated using their stems
* Train/Validation split is performed **after deduplication**
* Overlap between splits is explicitly checked and enforced to be zero

This ensures fair evaluation and realistic performance metrics.

---

## ğŸ“Š Training Setup

* **Optimizer:** Adam
* **Learning Rate:** 1e-4
* **Weight Decay:** 1e-3
* **Loss Functions:**

  * Fruit â†’ CrossEntropyLoss
  * Freshness â†’ CrossEntropyLoss

Metrics tracked **independently per task**:

* Training & Validation Loss (Fruit / Freshness)
* Training & Validation Accuracy (Fruit / Freshness)

---

## ğŸ“ˆ Results & Monitoring

The training loop records:

* ğŸ“‰ Separate loss curves for fruit and freshness
* ğŸ“ˆ Separate accuracy curves for fruit and freshness

This makes it easy to:

* Detect overfitting
* Identify task imbalance
* Monitor negative transfer between tasks

---

## ğŸŒ Inference on Internet Images

The project includes a utility to:

* Download a random image from the internet
* Apply inference-time preprocessing
* Predict:

  * Fruit type
  * Freshness state

Predictions are automatically decoded from class indices to human-readable labels.

---

## ğŸ›  Tech Stack

* **Python**
* **PyTorch & TorchVision**
* **ResNet50 (Transfer Learning)**
* **OpenCV / PIL**
* **Matplotlib**
* **Scikit-learn**

---

## ğŸš€ Future Improvements

* Task-weighted loss balancing
* Gradual unfreezing of backbone layers
* Confidence-based predictions
* Real-time webcam inference
* Deployment via FastAPI or Streamlit

---

## âœ… Key Takeaways

* Multi-task learning improves efficiency and representation sharing
* Careful loss & metric separation is critical
* Preventing data leakage is essential for trustworthy results

---

## ğŸ‘¨â€ğŸ’» Author @ Abdullah Yusuf
